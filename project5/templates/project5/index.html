{% extends 'base.html' %}
{% load static %}

{% block extra_css %}
  <link rel="stylesheet" href="{% static 'project2.css' %}">
  <link rel="stylesheet" href="{% static 'project5/styles.css' %}">
  <style>
    /* Center grid */
    .gw {
      display: grid;
      grid-template-columns: repeat(5, 48px);
      grid-auto-rows: 48px;
      gap: 6px;
      margin: 20px auto;
      justify-content: center;
    }
    .legend {
      display:flex;
      justify-content:center;
      gap:16px;
      margin-top:12px;
      flex-wrap:wrap;
    }

    /* Compact, aligned chart */
    .chart-card{
      margin:16px auto;
      padding:12px;
      border:1px solid #eee;
      border-radius:12px;
      background:#fbfbfb;
      max-width:560px;           /* tweak to shrink/grow the chart */
      text-align:center;
    }
    .chart-grid{
      display:grid;
      grid-auto-flow:column;
      grid-auto-columns:minmax(72px, 1fr);  /* one column per bar */
      justify-content:center;
      gap:24px;
      margin-top:8px;
    }
    .chart-col{
      display:grid;
      grid-template-rows: 110px auto auto;  /* fixed bar area height */
      align-items:end;                       /* bars sit on a common baseline */
      justify-items:center;
    }
    .bar{
      width:36px;
      border-radius:8px;
      /* height set by JS to fit into the 110px slot above */
    }
    .bar-label{
      margin-top:8px;
      font-size:12px;
      text-align:center;
      line-height:1.2;
      max-width:100%;
      word-break:break-word;
    }
    .bar-value{
      font-size:12px;
      color:#555;
      text-align:center;
    }
  </style>
{% endblock %}

{% block content %}
<div class="project2">

  <!-- Top nav home button -->
  <a href="{% url 'home:index' %}" class="home-button">Home</a>

  <h1>Project 5 ‚Äî Reinforcement Learning with Human Feedback</h1>
  <p class="lead">
    This project explores human-centric reinforcement learning by combining policy gradient
    methods with human preferences. You‚Äôll train a REINFORCE agent in a 5√ó5 grid-world,
    sample trajectories for comparison, and use human feedback to build a reward model
    and fine-tune the agent with RLHF (Reinforcement Learning with Human Feedback).
  </p>

  <!-- Tools -->
  <div style="display:flex; justify-content:center; margin-bottom:1rem;">
    <a href="{% url 'project5:reshuffle' %}"
       class="btn"
       style="display:inline-flex; align-items:center; gap:10px;
              padding:10px 18px; font-size:16px; font-weight:600; line-height:1.1;
              width:auto !important; min-width:unset !important; max-width:max-content;
              border-radius:10px; white-space:nowrap; text-decoration:none;">
      üîÄ Reshuffle Grid
    </a>
  </div>

  <!-- Grid -->
  <div class="gw">
    {% for row in grid %}
      {% for cell in row %}
        <div class="tile {{ cell.cls }}">{{ cell.char }}</div>
      {% endfor %}
    {% endfor %}
  </div>

  <!-- Legend -->
  <div class="legend">
    <div><span class="leg tile tile-mouse">üê≠</span> Mouse</div>
    <div><span class="leg tile tile-cheese">üßÄ</span> Cheese</div>
    <div><span class="leg tile tile-organic">üßÄ</span> Organic</div>
    <div><span class="leg tile tile-trap">‚ò†Ô∏è</span> Trap</div>
    <div><span class="leg tile tile-wall">üß±</span> Wall</div>
    <div><span class="leg tile tile-empty"></span> Empty</div>
  </div>

  <hr/>

  <!-- Task 1 -->
  <section>
    <h2>Train REINFORCE Policy</h2>
    <p class="desc">
      Learn a policy in a 5√ó5 grid-world by simulating trajectories and applying REINFORCE:
      estimate the policy gradient from returns and update the network to favor actions that
      lead to cheese (+10) while avoiding traps (‚àí50) and unnecessary moves (‚àí0.2).
    </p>

    <form method="post" action="{% url 'project5:train' %}" class="form-block">
      {% csrf_token %}
      {{ form.as_p }}
      <button type="submit" class="btn">Train</button>
    </form>

    {% if show_results %}
      <div class="metrics">
        <div><strong>Training complete.</strong></div>
        <div>Mean episodic return (eval): {{ mean_return|floatformat:2 }}</div>
        <div>Std episodic return (eval): {{ std_return|floatformat:2 }}</div>
      </div>
    {% endif %}

    {# ------- PERFORMANCE CHART (aligned + compact) ------- #}
    {% if chart_points %}
      <div class="chart-card">
        <strong>Performance chart</strong>
        <div id="chart" class="chart-grid" data-absmax="{{ chart_absmax|default:1 }}">
          {% for label, val in chart_points %}
            <div class="chart-col">
              <div class="bar" data-value="{{ val }}"></div>
              <div class="bar-label">{{ label }}</div>
              <div class="bar-value">{{ val|floatformat:2 }}</div>
            </div>
          {% endfor %}
        </div>
        <div style="font-size:12px;color:#777;margin-top:4px;">
          Bars scaled by max(|mean|) = {{ chart_absmax|floatformat:2 }}
        </div>
      </div>
    {% endif %}
    {# ----------------------------------------------------- #}
  </section>

  <hr/>

  <!-- Task 2 -->
  <section>
    <h2>Sample Trajectories & Give Preferences</h2>
    <p class="desc">
      Generate pairs of trajectories and let a human label which one is preferred.
      This feedback is collected to guide reward modeling in the next step.
    </p>

    {% if trained %}
      <div class="btn-row" style="gap:.5rem; display:flex; justify-content:center;">
  <a class="btn"
     href="{% url 'project5:sample' %}"
     style="display:inline-flex; align-items:center; justify-content:center;
            padding:12px 28px; font-size:16px; font-weight:600; line-height:1.2;
            border-radius:12px; width:auto; min-width:260px; 
            white-space:nowrap; text-align:center;">
    Sample trajectories{% if num_prefs %} (Preferences: {{ num_prefs }}){% endif %}
  </a>
</div>


    {% else %}
      <p>Train the model first to enable trajectory sampling.</p>
    {% endif %}
  </section>

  <hr/>

  <!-- Task 3 -->
  <section>
    <h2>Learn Reward & RLHF Fine-Tune</h2>
    <p class="desc">
      Use the collected human preferences to train a reward model, then fine-tune the policy
      with Reinforcement Learning from Human Feedback (RLHF) to align better with human choices.
    </p>

    {% if trained %}
      <form method="post" action="{% url 'project5:fit_reward' %}" class="form-block">
        {% csrf_token %}
        <button type="submit" class="btn" {% if num_prefs|default:0 < 1 %}disabled{% endif %}>
          Fit reward from {{ num_prefs|default:0 }} preferences
        </button>
      </form>
      
      <form method="post" action="{% url 'project5:rlhf_retrain' %}" style="display:flex;gap:8px;align-items:center;flex-wrap:wrap;">
        {% csrf_token %}
        <label>KL Œ≤ <input name="kl_beta" type="number" step="0.001" value="0.01" style="width:80px"></label>
        <label>Epochs <input name="epochs" type="number" value="50" style="width:80px"></label>
        <label>LR <input name="lr" type="text" value="0.05" style="width:90px"></label>
        <label>Max steps <input name="max_steps" type="number" value="50" style="width:90px"></label>
        <button class="btn" type="submit" {% if not reward_fit %}disabled{% endif %}>RLHF fine-tune</button>
      </form>

      <div class="results" style="margin-top:8px;">
        <div>Reward fitted: {{ reward_fit }}</div>
        <div>RLHF done: {{ rlhf_done }}</div>
      </div>
    {% else %}
      <p></p>
    {% endif %}
  </section>

  <hr/>

  <!-- Reset -->
  <section>
    <form method="post" action="{% url 'project5:reset' %}" class="form-block">
      {% csrf_token %}
      <button type="submit" class="btn"
              style="background:#fff3cd; border-color:#ffe69c; color:#000;">
        Reset Session
      </button>
    </form>
</section>


</div>

<!-- Chart script (keep only once) -->
<script>
(function(){
  var chart = document.getElementById('chart');
  if(!chart) return;

  var absmax = parseFloat(chart.getAttribute('data-absmax') || '1');
  if(!(absmax > 0)) absmax = 1;

  // bars live in a fixed 110px slot; fill a portion of it
  var slotHeight = 110;
  chart.querySelectorAll('.bar').forEach(function(bar){
    var v = parseFloat(bar.getAttribute('data-value') || '0');
    var h = Math.round((slotHeight - 6) * Math.abs(v) / absmax); // padding from top
    if (h < 3) h = 3;
    bar.style.height = h + 'px';
    bar.style.border = '1px solid ' + (v >= 0 ? '#9ec5fe' : '#f4a6a6');
    bar.style.background = (v >= 0 ? '#cfe2ff' : '#ffe0e0');
    bar.style.alignSelf = 'end'; // sit on the baseline within the slot
  });
})();
</script>
{% endblock %}
